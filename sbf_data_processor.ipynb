{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:orange\">Data Processor</span> for BitCoin/Bank Secondary Issuances Market Timing Strategy\n",
    "\n",
    "This sheet starts the process of coding a backtest for a strategy timing the US equity market using the bank secondary issuances as a signal. The first step is to load data on stock returns for BTC and banks and the dates of secondary issuances, and organize it so we can access it as we backtest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processor required functions\n",
    "\n",
    "According to the pseudo-code above, the <span style=\"color:green\">Data Processor</span> needs to do the following tasks:\n",
    "1. Load all the necessary raw data (in constructor)\n",
    "1. Return an array of unique dates in the raw data (`unique_dates()`)\n",
    "1. For a given date, return a signal DataFrame containing all the latest signals for the appropriate universe of securities (`signal_df_for_date(date)`)\n",
    "1. For a given date, return a price DataFrame containing the latest prices for all securities potentially in the portfolio, including those not in the current investable universe (`price_df_for_date(date)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from constants import holding_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class here\n",
    "class SBFDataProcessor():\n",
    "    \n",
    "    # Path to where we store the data\n",
    "    data_folder_path = Path('data') \n",
    "\n",
    "    # Minimum share price to open a new position\n",
    "    min_share_price = 0\n",
    "\n",
    "    # Start Date\n",
    "    start_date = pd.to_datetime('2014-09-17')\n",
    "        \n",
    "    # Constructor, loads/cleans/merges data as needed\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Load price data: monthly 1926-2022 sample of mkt_rf \n",
    "        self.price_df = pd.read_csv(self.data_folder_path / 'yf-prices.csv')\n",
    "        \n",
    "        # Parse the yyyyMMdd int dates into DateTime64\n",
    "        # Based on formatting strings here\n",
    "        # https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "\n",
    "        # Define prices of all stocks and Crypto in universe\n",
    "        self.price_df['date'] = pd.to_datetime(self.price_df.loc[:,'Date'])\n",
    "        self.price_df['prc'] = self.price_df['Adj Close']\n",
    "        self.price_df['security_id'] = self.price_df['Ticker']\n",
    "        self.price_df['ret_next'] = safe_lead_lag(self.price_df.loc[:,'ret'],self.price_df.loc[:,'security_id'],1)\n",
    "        self.price_df['ret_holding_period'] = safe_lead_lag(self.price_df.loc[:,'ret'],self.price_df.loc[:,'security_id'], holding_period)\n",
    "        self.price_df = self.price_df[['date', 'prc', 'security_id', 'ret', 'ret_next', 'ret_holding_period']]\n",
    "        self.price_df = self.price_df[self.price_df['date'] >= self.start_date]\n",
    "\n",
    "        # Define all signals in traing strategy\n",
    "        self.signal_df = pd.read_csv(self.data_folder_path / 'signal-raw.csv')\n",
    "        self.signal_df['date'] = pd.to_datetime(self.signal_df.loc[:,'Date'])\n",
    "        self.signal_df['security_id'] = self.signal_df['Ticker']\n",
    "        self.signal_df['size'] = self.signal_df['Offer Size (M)']\n",
    "        self.signal_df = self.signal_df[['date', 'security_id', 'size']]\n",
    "        self.signal_df = self.signal_df[self.signal_df['date'] >= self.start_date]\n",
    "        \n",
    "    # Returns an array with the unique dates for which we have loaded data\n",
    "    # Uses from the price_df since that's how frequency we can update portfolio value\n",
    "    # Filters all dates in price_df to return only dates for which we have signals as well\n",
    "    def unique_dates(self):\n",
    "        price_dates = pd.Series( np.sort(self.price_df.loc[:,'date'].unique()) )\n",
    "        return price_dates[1:].array\n",
    "    \n",
    "    # Returns a filtered version of the passed DataFrame,\n",
    "    # with all observations deemed too illiquid removed\n",
    "    # Liquidity requirements:\n",
    "    #  - price >= $3\n",
    "    def liquidity_filter(self,df):\n",
    "        return df.loc[ df.loc[:,'prc'] >= self.min_share_price,:]\n",
    "    \n",
    "    # Returns a DataFrame containing one row for all securities in price_df as of date.\n",
    "    # Columns must include:\n",
    "    # - 'date': date on which price data observed\n",
    "    # - 'security_id': a security identifier\n",
    "    # - 'prc': price on date\n",
    "    # - 'ret': return from previous date to date\n",
    "    # Ignores liquidity and future-return availability requirements\n",
    "    # To be used only for closing decisions and execution decisions\n",
    "    # Some of the returned stocks cannot be traded\n",
    "    def price_df_for_date(self,date):\n",
    "        price_date_df = self.price_df.loc[ self.price_df.loc[:,'date'] == date, :]\n",
    "        return price_date_df\n",
    "    \n",
    "    # Returns a DataFrame where each row is a security in the strategy's universe,\n",
    "    # Columes must include:\n",
    "    # - 'date': date on which price data observed\n",
    "    # - 'security_id': a security identifier\n",
    "    # - whatever signals the trading rule needs to decide which securities to open new positions in\n",
    "    #   - In this case, return cshoq, prccq, and ceqq so trading rule can compute B/M ratio\n",
    "    #\n",
    "    # Also responsible for applying whatever liquidity filters are wanted to narrow universe,\n",
    "    # and check that we have future return data (no point in backtesting if we don't know what happens next)\n",
    "    def signal_df_for_date(self,date):\n",
    "        # Merge on secruity id\n",
    "        merged_df = pd.merge(self.price_df, self.signal_df, on = 'security_id', suffixes=['_price', '_signal'])\n",
    "\n",
    "        # Find all dates of the price is a max of 3 days after date of signal\n",
    "        merged_df = merged_df[(merged_df['date_price']-merged_df['date_signal']>= pd.Timedelta(days=0)) & (merged_df['date_price']-merged_df['date_signal']<= pd.Timedelta(days=3))]\n",
    "        \n",
    "        # Group by security_id and date_signal to find newest date_price after signal\n",
    "        merged_df = merged_df.sort_values(by=['security_id', 'date_price']).groupby(by=['security_id', 'date_signal']).first().reset_index()\n",
    "\n",
    "        # Set date to the date of the price (action)\n",
    "        merged_df['date'] = merged_df['date_price']\n",
    "\n",
    "        # Apply liquidity filter\n",
    "        merged_df = self.liquidity_filter(merged_df)\n",
    "\n",
    "        # Find and add BTC prices to hedge shorting banks\n",
    "        btc = self.price_df[self.price_df['security_id'] == \"BTC-USD\"]\n",
    "        filtered_btc = btc[btc['date'].isin(merged_df['date'].unique())]\n",
    "\n",
    "        merged_df = pd.concat([merged_df, filtered_btc])\n",
    "\n",
    "        merged_df = merged_df[ np.isfinite(merged_df['ret_next'])]\n",
    "        merged_df = merged_df[ np.isfinite(merged_df['ret_holding_period'])]\n",
    "\n",
    "        merged_df = merged_df[['security_id', 'prc', 'ret', 'ret_next', 'ret_holding_period', 'size', 'date']]\n",
    "        \n",
    "        return merged_df[merged_df['date'] == date]\n",
    "\n",
    "###################################################################\n",
    "# Helper methods, do not modify\n",
    "###################################################################\n",
    "\n",
    "# Function safe_lead_lag returns a new Series with the lead/lagged values\n",
    "#  but only when a group is the same for the lead/lag\n",
    "# Inputs:\n",
    "# - data_series: data we want to lead/lag\n",
    "# - group_series: grouping we want to be the same for the lead/lag to be value\n",
    "# requires data_series and group_series already by sorted by group_series\n",
    "# so that all alike values of group_series are adjacent,\n",
    "# meaning group_series should look like:\n",
    "#    g_0\n",
    "#    g_0\n",
    "#    g_0\n",
    "#    g_0\n",
    "#    g_1\n",
    "#    g_1\n",
    "#    g_2\n",
    "#    g_2 \n",
    "#    ...\n",
    "# where g_i indicates the observation is in group i,\n",
    "# and once the first g_{i+1} appears no more g_i values appear\n",
    "# \n",
    "# lead_lag > 0 returns a data_series with values of data_series lead_lag rows ahead\n",
    "# as long as group_series remains the same, NaN if group different\n",
    "# lead_lag < 0 returns a data_series with values of data_series -lead_lag rows behind \n",
    "# (same as lead_lag rows ahead) as long as group_series remains the same, NaN if group different\n",
    "def safe_lead_lag(data_series,group_series,lead_lag): \n",
    "    df = pd.DataFrame({ 'data': data_series, 'group': group_series })\n",
    "    return df.groupby(['group'])['data'].shift(-lead_lag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
